{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "417a9e80-e1be-4db4-bfa5-831570a39fe3",
   "metadata": {},
   "source": [
    "# HF Transformers 核心模块学习：Pipelines\n",
    "\n",
    "**Pipelines**（管道）是使用模型进行推理的一种简单易上手的方式。\n",
    "\n",
    "这些管道是抽象了 Transformers 库中大部分复杂代码的对象，提供了一个专门用于多种任务的简单API，包括**命名实体识别、掩码语言建模、情感分析、特征提取和问答**等。\n",
    "\n",
    "**通俗解释**  \n",
    "Pipelines 就像是一条简单的“生产线”，把模型加载、数据预处理、推理以及结果处理的复杂工作都封装起来。这样，无论是做情感分析、问答、命名实体识别还是图像分类，都只需要调用一行代码，省去了繁琐的配置和调试步骤。\n",
    "\n",
    "**常用任务表格**\n",
    "\n",
    "| Modality                    | Task                              | Description                                                         | Pipeline API                                         |\n",
    "| --------------------------- | --------------------------------- | ------------------------------------------------------------------- | ---------------------------------------------------- |\n",
    "| Audio                       | Audio classification              | 为音频文件分配一个标签                                              | `pipeline(task=\"audio-classification\")`              |\n",
    "|                             | Automatic speech recognition      | 将音频文件中的语音转换为文本                                          | `pipeline(task=\"automatic-speech-recognition\")`      |\n",
    "| Computer vision             | Image classification              | 为图像分配一个标签                                                  | `pipeline(task=\"image-classification\")`              |\n",
    "|                             | Object detection                  | 预测图像中目标对象的边界框和类别                                      | `pipeline(task=\"object-detection\")`                  |\n",
    "|                             | Image segmentation                | 为图像中每个像素分配标签（支持语义、全景和实例分割）                   | `pipeline(task=\"image-segmentation\")`                |\n",
    "|                             | Zero-shot image classification    | 对未见过的类别进行图像分类（最新常用功能）                             | `pipeline(task=\"zero-shot-image-classification\")`    |\n",
    "| Natural language processing | Text classification (sentiment)   | 为给定文本序列分配一个标签（如情感分析）                              | `pipeline(task=\"sentiment-analysis\")`                |\n",
    "|                             | Token classification (NER)        | 为文本中每个 token 分配标签（如人、组织、地点等命名实体识别）            | `pipeline(task=\"ner\")`                               |\n",
    "|                             | Question answering                | 根据上下文和问题，在文本中提取答案                                    | `pipeline(task=\"question-answering\")`                |\n",
    "|                             | Summarization                     | 为文本或文档生成摘要                                                 | `pipeline(task=\"summarization\")`                     |\n",
    "|                             | Translation                       | 将文本从一种语言翻译为另一种语言                                      | `pipeline(task=\"translation\")`                       |\n",
    "|                             | Text generation                   | 根据给定提示生成自然语言文本（最新常用功能）                           | `pipeline(task=\"text-generation\")`                   |\n",
    "|                             | Fill-mask                         | 根据上下文预测被掩盖的词语（最新常用功能）                             | `pipeline(task=\"fill-mask\")`                         |\n",
    "|                             | Zero-shot classification          | 对文本进行未见过类别的分类（最新常用功能）                             | `pipeline(task=\"zero-shot-classification\")`          |\n",
    "| Multimodal                | Document question answering       | 根据给定文档和问题回答文档相关的问题                                  | `pipeline(task=\"document-question-answering\")`       |\n",
    "|                           | Visual Question Answering         | 给定图像和问题，回答有关图像的问题                                   | `pipeline(task=\"vqa\")`                               |\n",
    "|                           | Image captioning                  | 为图像生成描述性文字（最新常用功能）                                  | `pipeline(task=\"image-to-text\")`                     |\n",
    "\n",
    "- 在模型列表中，页面左侧可以看到所有支持的模型和任务：https://huggingface.co/models\n",
    "- 选中任意一个模型，如 https://huggingface.co/deepseek-ai/DeepSeek-R1 ，有对应的Pipeline任务，通常在第一个。\n",
    "- Pipelines 已支持的完整任务列表：https://huggingface.co/docs/transformers/task_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f2e3c-a185-4164-ab8b-3b8c98c3b4a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pipeline API\n",
    "\n",
    "**Pipeline API** 是对所有其他可用管道的包装。它可以像任何其他管道一样实例化，它将模型加载、数据预处理、推理和结果处理等复杂步骤全部封装起来，从而使 AI 推理的调用变得像调用普通函数一样直观，既保留了专业性又让使用变得简单易懂。\n",
    "\n",
    "![](docs/images/pipeline_func.png)\n",
    "\n",
    "---\n",
    "\n",
    "### 为什么使用 Pipeline API？\n",
    "\n",
    "- **简单易用**：只需几行代码，就能完成从输入到输出的整个流程。\n",
    "- **降低学习成本**：你不需要深入理解模型内部的工作机制，就能实现文本分类、问答、图像识别等任务。\n",
    "- **封装复杂性**：内部已经帮你处理好了模型加载、数据转换和结果解释等步骤。\n",
    "\n",
    "---\n",
    "\n",
    "### 使用 Pipeline API 实现 Text Classification 任务\n",
    "\n",
    "**Text classification**(文本分类)与任何模态中的分类任务一样，文本分类将一个文本序列（可以是句子级别、段落或者整篇文章）标记为预定义的类别集合之一。文本分类有许多实际应用，其中包括：\n",
    "\n",
    "- **情感分析**：判断文本是表达积极情绪还是消极情绪，帮助在政治、金融、市场等领域做出决策。\n",
    "- **内容分类**：根据主题对文本进行分类，如过滤新闻、社交媒体内容等。\n",
    "\n",
    "\n",
    "下面以 `Text classification` 中的情感分析任务为例，展示如何使用 Pipeline API。\n",
    "\n",
    "模型主页：https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef33288-018d-4a01-bb96-092272d3ec99",
   "metadata": {},
   "source": [
    "Hugging Face 在 `pipeline(\"sentiment-analysis\")` 里使用的默认模型，通常是  \n",
    "**[distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)**。\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 这个默认模型是什么？\n",
    "\n",
    "1. **DistilBERT** 版本：  \n",
    "   - DistilBERT 是对原始 BERT 做了**模型蒸馏 (distillation)** 后得到的一个轻量化模型，比 BERT 体积更小、推理速度更快，但尽量保留了 BERT 的语言理解能力。\n",
    "\n",
    "2. **fine-tuned on SST-2**：  \n",
    "   - 它在 Stanford Sentiment Treebank (SST-2) 数据集上进行了**微调 (fine-tuning)**，用来做**英文情感分类**（比如区分 “正面 / 负面”）。\n",
    "\n",
    "3. **无大小写 (uncased)**：  \n",
    "   - 它使用的是“uncased”词表，意味着它不区分大小写（“Apple” 和 “apple” 最终在分词时被当作同一个词处理）。\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 它是语言模型吗？\n",
    "\n",
    "- **BERT/DistilBERT** 本质是 **“预训练语言模型”** 的一种，但它使用 **掩码语言建模（MLM）** 技术进行预训练，并不直接像 GPT 那样生成文本。  \n",
    "- 不过，这里我们得到的 **“finetuned-sst-2”** 版本已经是针对**情感分类**任务做过专门训练，因此更准确地说，它是**一个针对情感分析下游任务的分类模型**。\n",
    "\n",
    "换句话说，它的核心还是基于 **BERT 家族** 的预训练语言模型，但是它现在的使用场景是**句子分类**而非通用的文本生成或语言建模。\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 使用特点\n",
    "\n",
    "- **适合英文文本** 的**正/负向情感分析**。对于诸如“good/bad”、“love/hate”之类的表达能判断得比较准确。  \n",
    "- 如果输入里面包含**中文或其它语言**，这个模型往往无法正确分词、效果也会很差，建议换一个专门针对中文或多语言情感分析的模型。\n",
    "\n",
    "---\n",
    "\n",
    "## 4. 总结\n",
    "\n",
    "1. **默认模型**：`distilbert-base-uncased-finetuned-sst-2-english`  \n",
    "2. **本质**：基于 BERT (DistilBERT) 的**预训练语言模型**，再进行**情感分类微调**  \n",
    "3. **使用场景**：英文句子的正面/负面情感分析  \n",
    "4. **若需中文**：请选择专门的中文情感分析模型（如 `uer/roberta-base-finetuned-jd-binary-chinese` 等）  \n",
    "\n",
    "因此，如果你在 Python 中直接调用 `pipeline(\"sentiment-analysis\")`，没指定模型，默认就会下载并使用这个 DistilBERT 英文情感分析模型来给你做推理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55837de-d616-43be-bdf1-ffa97c5d4054",
   "metadata": {},
   "source": [
    "**情感分类问题**的期望结果分值应该在 **0.97 以上**，其实这是一个比较高的标准，是否合理需要根据具体的情况来判断。通常来说，分类模型的评估指标是 **准确率 (Accuracy)**、**精确度 (Precision)**、**召回率 (Recall)**、**F1 分数 (F1 Score)** 等。\n",
    "\n",
    "### 1. **0.97 的准确率标准**：  \n",
    "对于情感分析任务，0.97 的准确率确实是非常高的。这里有几点要考虑：\n",
    "\n",
    "- **数据集的难度**：如果是处理相对简单的、清晰标注的情感数据集（例如：SST-2），这种准确率可能更容易达到。但如果是复杂的情感分析任务（例如：讽刺、双关语、隐含情感的理解），0.97 的准确率就相对较难达到。\n",
    "- **标注的质量和任务的范围**：如果情感分析的任务本身非常精细化（比如分类成多个情感类别：愤怒、喜悦、悲伤等），要达到 0.97 的准确率可能比较困难。相反，如果只是正面和负面（比如二分类任务），那么高准确率是更为容易实现的。\n",
    "- **数据量**：训练模型所用的数据量越大，通常模型的表现会越好，因此如果模型的训练数据很少，达到 0.97 的准确率可能非常难。\n",
    "\n",
    "### 2. **情感分析模型的普遍表现**\n",
    "\n",
    "以 **SST-2** 数据集为例，DistilBERT（你提到的默认模型）在经过微调后的准确率大约能达到 **90% 到 95%** 左右，这已经是非常好的结果了。对于 **BERT** 或 **RoBERTa** 等大模型，可能会稍微提高一些准确率，但一般不会超过 98%。\n",
    "\n",
    "在实际使用中，准确率并非唯一的衡量标准。**F1 分数**（精确度与召回率的调和平均值）往往更重要，尤其是在样本不均衡时，准确率可能不能全面反映模型的性能。\n",
    "\n",
    "### 3. **不同任务的目标**\n",
    "\n",
    "对于情感分析任务，尤其是在一些 **二分类任务**（例如判断一句话是正面还是负面情感）中，目标的准确率有时候并不需要达到 0.97 以上，尤其是在 **生产环境中**，很多时候 90% 左右已经能提供较好的效果，用户可以接受一些误判。相比之下，达到 0.97 的准确率则可能意味着你需要：\n",
    "- 处理非常简单的文本数据，或者\n",
    "- 模型进行了非常精细的调优。\n",
    "\n",
    "### 4. **评估指标的选择**\n",
    "\n",
    "除了准确率，还有其他重要的指标可以帮助你更全面地了解模型表现：\n",
    "\n",
    "- **精确度 (Precision)**：模型预测为正类的样本中，真正是正类的比例。如果你对减少假阳性（错误地预测为正类）更为关心，精确度会更重要。\n",
    "- **召回率 (Recall)**：模型能够识别出所有正类样本的比例。如果你更关心漏掉负面的情感，召回率就是一个需要重点关注的指标。\n",
    "- **F1 分数**：精确度和召回率的调和平均值，它平衡了精确度和召回率。通常情况下，F1 分数比准确率更能反映模型的真实表现，尤其是在类别不平衡时。\n",
    "\n",
    "### 5. **结论**\n",
    "\n",
    "- **0.97 以上的准确率**：对于大部分情感分析任务来说，0.97 的准确率是比较高的标准，可能比较难实现，尤其是任务比较复杂或数据较少的情况下。如果你的模型准确率能达到 0.90-0.95 之间，就已经是非常不错的表现。\n",
    "- **高标准有道理**：如果你的数据集较简单，且标注质量很高，目标准确率是 0.97 或以上是合理的。但对于更复杂的场景，95% 以上可能已经非常优秀。\n",
    "- **评估指标综合考虑**：除了准确率，**F1 分数**等其他评估指标也应综合考虑。准确率较高但 F1 分数较低，可能意味着模型存在较多的误分类问题。\n",
    "\n",
    "综上，**0.97 以上**作为目标并不是不合理，但在许多情感分析任务中，能达到 0.90 到 0.95 之间通常已经是非常不错的表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353da9d1-29e9-4255-bfc5-adc2b20af384",
   "metadata": {},
   "source": [
    "**`distilbert-base-uncased-finetuned-sst-2-english`** 这个模型针对 **英文** 情感分析训练，主要词表（vocabulary）针对的是英文单词，对于中文字符基本没有有效的表示方式。你把中文文本喂给它时，它还是会输出一个结果，但这个结果大概率并没有实际意义，也可以认为“它不认得中文”。\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 为什么英文模型不适用于中文\n",
    "1. **预训练词表差异**：此类英文模型对中文字符（Unicode）没有训练过；当它看到中文时，一般会被强行分词为一堆“[UNK]”（未知标记）或者奇怪的 token，得到的表征几乎没有可用信息。\n",
    "2. **训练语料差异**：它是在英文句子上做的预训练和微调，对中文的语法、表达并不了解。\n",
    "3. **情感标注差异**：它只见过英文中正面/负面表述的模式，中文中的“喜怒哀乐”各种表述形式并未学习到。\n",
    "\n",
    "因此，用它直接做中文文本的情感分析，模型输出结果并不可信。\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 想分析中文情感，应该选什么模型？\n",
    "\n",
    "如果你的目标是做**中文情感分析**，可以考虑**在 Hugging Face** 上找一些已经针对中文进行预训练并且微调过的模型，比如：\n",
    "\n",
    "- [hfl/chinese-roberta-wwm-ext](https://huggingface.co/hfl/chinese-roberta-wwm-ext) 或 [hfl/chinese-bert-wwm-ext](https://huggingface.co/hfl/chinese-bert-wwm-ext)  \n",
    "  - 这些是中文语言模型，可以拿来继续做情感分类微调。  \n",
    "- 一些开箱即用的**中文情感分析**模型，比如 [uer/roberta-base-finetuned-jd-binary-chinese](https://huggingface.co/uer/roberta-base-finetuned-jd-binary-chinese)  \n",
    "  - 在京东商品评论或其它中文情感语料上微调过，直接可拿来做中文情感分类。\n",
    "\n",
    "直接换成中文模型后，再输入中文，就能得到**更合理**的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c38e82-e8f6-4af0-b257-b46f446aa249",
   "metadata": {
    "tags": []
   },
   "source": [
    "## transformers 自定义模型下载的路径\n",
    "\n",
    "在transformers自定义模型下载的路径方法\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/mnt/new_volume/hf'\n",
    "os.environ['HF_HUB_CACHE'] = '/mnt/new_volume/hf/hub'\n",
    "print(os.environ.get(\"HF_HUB_URL\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49a3cf25-77d7-4a1a-8c51-49b6e665f4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/new_volume/hf\n",
      "/mnt/new_volume/hf/hub\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/mnt/new_volume/hf'\n",
    "os.environ['HF_HUB_CACHE'] = '/mnt/new_volume/hf/hub'\n",
    "print(os.environ.get(\"HF_HOME\"))\n",
    "print(os.environ.get(\"HF_HUB_CACHE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9684ec5f-9460-4876-9883-69380eacb0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8957212567329407}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 仅指定任务时，使用默认模型（不推荐）\n",
    "# 默认模型是英文识别，非英文文本都会被判断为NAGATIVE\n",
    "pipe = pipeline(\"sentiment-analysis\", model=\"/mnt/new_volume/hf/hub/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "pipe(\"今儿上海可真冷啊\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a12486-952a-447d-9e90-6b041349a26e",
   "metadata": {},
   "source": [
    "### 测试更多示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee67f529-3d32-4834-b29a-e51a65cf4d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8923922181129456}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"我觉得这家店糖醋肉的味道一般\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e104034-94ca-4370-8d35-438501c29ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.7035934925079346}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 默认使用的模型 distilbert-base-uncased-finetuned-sst-2-english \n",
    "# 并未针对中文做太多训练，中文的文本分类任务表现未必满意\n",
    "pipe(\"你学东西真的好快，理论课一讲就明白！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c3d11aa-d523-491c-8910-bdc8aba49487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9974971413612366}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 替换为英文后，文本分类任务的表现立刻改善\n",
    "pipe(\"You learn things really quickly. You understand the English class as soon as it is taught.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09df7300-2f0d-4bc4-9572-0631658e8253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9989988207817078}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Today Shanghai is very hot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507dbfc3-5347-4b82-8ea1-4e6c3d81c07f",
   "metadata": {},
   "source": [
    "### 批处理调用模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1390396e-1af8-497f-85d9-6c9e984b4609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9976884126663208},\n",
       " {'label': 'NEGATIVE', 'score': 0.99625563621521},\n",
       " {'label': 'POSITIVE', 'score': 0.998001754283905}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = [\n",
    "    \"Today Shanghai is vary cold.\",\n",
    "    \"I think the taste of the meat in this store is average.\",\n",
    "    \"You learn things really quickly. You understand the japanese class as soon as it is taught.\"\n",
    "]\n",
    "\n",
    "pipe(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3686758b-d7f7-4df9-889d-e63af47a138a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d5a27fe-87d0-45fc-a31a-9a8db23e290a",
   "metadata": {},
   "source": [
    "## 使用 Pipeline API 调用更多预定义任务\n",
    "\n",
    "## Natural Language Processing(NLP)\n",
    "\n",
    "**NLP**(自然语言处理)任务是最常见的任务类型之一，因为文本是我们进行交流的一种自然方式。要将文本转换为模型可识别的格式，需要对其进行分词。这意味着将一系列文本划分为单独的单词或子词（标记），然后将这些标记转换为数字。结果就是，您可以将一系列文本表示为一系列数字，并且一旦您拥有了一系列数字，它就可以输入到模型中来解决各种NLP任务！\n",
    "\n",
    "上面演示的 文本分类任务，以及接下来的标记、问答等任务都属于 NLP 范畴。\n",
    "\n",
    "### Token Classification\n",
    "\n",
    "在任何NLP任务中，文本都经过预处理，将文本序列分成单个单词或子词。这些被称为tokens。\n",
    "\n",
    "**Token Classification**（Token分类）将每个token分配一个来自预定义类别集的标签。\n",
    "\n",
    "两种常见的 Token 分类是：\n",
    "\n",
    "- 命名实体识别（NER）：根据实体类别（如组织、人员、位置或日期）对token进行标记。NER在生物医学设置中特别受欢迎，可以标记基因、蛋白质和药物名称。\n",
    "- 词性标注（POS）：根据其词性（如名词、动词或形容词）对标记进行标记。POS对于帮助翻译系统了解两个相同的单词如何在语法上不同很有用（作为名词的银行与作为动词的银行）。\n",
    "\n",
    "模型主页：https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c2832f-2e31-4712-b453-ddf894b4b2d4",
   "metadata": {},
   "source": [
    "Hugging Face 的 `pipeline` API 支持多种预定义 NLP 任务，以下是对 Token Classification 及其他常见任务的扩展说明和优化建议：\n",
    "\n",
    "---\n",
    "\n",
    "### 一、Token Classification 任务优化\n",
    "#### 1. **命名实体识别（NER）**\n",
    "示例中使用的默认模型 `dbmdz/bert-large-cased-finetuned-conll03-english` 是一个在 CoNLL-2003 数据集上微调的模型，适用于英文 NER。建议明确指定模型名称和版本以提升稳定性：\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# 显式指定模型和任务类型\n",
    "ner_pipeline = pipeline(\n",
    "    task=\"ner\",\n",
    "    model=\"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "    revision=\"f2482bf\"  # 可选，指定模型版本\n",
    ")\n",
    "result = ner_pipeline(\"Apple was founded by Steve Jobs in Cupertino.\")\n",
    "print(result)\n",
    "```\n",
    "输出示例：\n",
    "```text\n",
    "[{'entity': 'B-ORG', 'score': 0.98, 'word': 'Apple'}, \n",
    " {'entity': 'B-PER', 'score': 0.99, 'word': 'Steve Jobs'}, \n",
    " {'entity': 'B-LOC', 'score': 0.97, 'word': 'Cupertino'}]\n",
    "```\n",
    "\n",
    "#### 2. **词性标注（POS）**\n",
    "若需词性标注，可使用支持多任务的模型（如 `vblagoje/bert-english-uncased-finetuned-pos`）：\n",
    "```python\n",
    "pos_pipeline = pipeline(\n",
    "    task=\"token-classification\",\n",
    "    model=\"vblagoje/bert-english-uncased-finetuned-pos\",\n",
    "    aggregation_strategy=\"simple\"  # 合并连续同类标记\n",
    ")\n",
    "result = pos_pipeline(\"The quick brown fox jumps over the lazy dog.\")\n",
    "print(result)\n",
    "```\n",
    "输出示例：\n",
    "```text\n",
    "[{'entity_group': 'DET', 'word': 'The', 'score': 0.99},\n",
    " {'entity_group': 'ADJ', 'word': 'quick', 'score': 0.98},\n",
    " ...]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 二、其他预定义 NLP 任务示例\n",
    "#### 1. **文本分类（Text Classification）**\n",
    "```python\n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "result = classifier(\"Transformers library simplifies NLP tasks!\")\n",
    "# 输出：[{'label': 'POSITIVE', 'score': 0.999}]\n",
    "```\n",
    "\n",
    "#### 2. **问答系统（Question Answering）**\n",
    "```python\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "context = \"Hugging Face is a company based in New York.\"\n",
    "answer = qa_pipeline(question=\"Where is Hugging Face located?\", context=context)\n",
    "# 输出：{'answer': 'New York', 'score': 0.92}\n",
    "```\n",
    "\n",
    "#### 3. **文本生成（Text Generation）**\n",
    "```python\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "text = generator(\"Artificial intelligence will\", max_length=50, num_return_sequences=2)\n",
    "# 输出两段不同生成的文本\n",
    "```\n",
    "\n",
    "#### 4. **文本摘要（Summarization）**\n",
    "```python\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summary = summarizer(\"Long input text about climate change...\", max_length=100)\n",
    "# 输出摘要后的文本\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 三、最佳实践建议\n",
    "1. **显式指定模型**  \n",
    "   生产环境中应避免依赖默认模型，明确指定模型名称和版本（如 `model=\"bert-base-uncased\"`）。\n",
    "\n",
    "2. **参数优化**  \n",
    "   - `aggregation_strategy`：在 NER 中合并连续实体（如 \"New York\" 合并为单个实体）。\n",
    "   - `max_length` 和 `truncation`：处理长文本时避免截断错误。\n",
    "\n",
    "3. **多语言支持**  \n",
    "   针对非英文任务，选择多语言模型（如 `bert-base-multilingual-cased`）。\n",
    "\n",
    "4. **性能优化**  \n",
    "   - 使用 `device` 参数启用 GPU 加速（如 `device=0` 表示使用第一块 GPU）。\n",
    "   - 批处理输入提升效率：`results = pipeline(texts, batch_size=8)`。\n",
    "\n",
    "---\n",
    "\n",
    "### 四、任务扩展场景\n",
    "| 任务类型               | 典型应用场景                     | 推荐模型示例                          |\n",
    "|------------------------|----------------------------------|---------------------------------------|\n",
    "| **命名实体识别（NER）** | 医疗病历解析、法律文件分析       | `dslim/bert-base-NER` (生物医学领域) |\n",
    "| **情感分析**           | 电商评论分析、舆情监控           | `nlptown/bert-base-multilingual-uncased-sentiment` |\n",
    "| **文本翻译**           | 多语言内容生成                   | `Helsinki-NLP/opus-mt-zh-en` (中译英) |\n",
    "\n",
    "---\n",
    "\n",
    "### 五、引用说明\n",
    "- 关于 Token Classification 的模型配置和 NER/POS 实现细节可参考[网页2]。\n",
    "- Pipeline API 的模型加载和参数设置方法详见[网页6]。\n",
    "- 生产环境中的最佳实践建议来自[网页9]的问答系统配置案例。\n",
    "\n",
    "通过明确指定模型、调整参数及选择合适任务类型，可充分发挥 Transformers 库的多任务处理能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad3e4f8-014f-421a-b68a-aaf53b5af964",
   "metadata": {},
   "source": [
    "当你在 Hugging Face 的 `pipeline` API 中未显式指定模型时，系统会自动选择一个默认模型。以下是关于此警告的详细解读和优化建议：\n",
    "\n",
    "---\n",
    "\n",
    "### 一、警告原因分析\n",
    "1. **默认模型的局限性**  \n",
    "   - 当调用 `pipeline(task=\"ner\")` 时未指定模型，Transformers 库会自动选择任务相关的默认模型（如 `dbmdz/bert-large-cased-finetuned-conll03-english`）。\n",
    "   - **潜在风险**：默认模型可能并非最适合你的任务场景，且不同版本的库可能会调整默认模型，导致结果不一致。\n",
    "\n",
    "2. **生产环境不推荐**  \n",
    "   - 警告明确提示 `Using a pipeline without specifying a model name and revision in production is not recommended`，原因包括：\n",
    "     - **版本控制缺失**：未指定模型版本（`revision`）可能导致未来更新时模型行为变化。\n",
    "     - **性能不可控**：默认模型的推理速度、内存占用可能不满足生产需求。\n",
    "\n",
    "---\n",
    "\n",
    "### 二、解决方案与最佳实践\n",
    "#### 1. **显式指定模型**\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# 指定模型名称和版本（推荐）\n",
    "ner_pipeline = pipeline(\n",
    "    task=\"ner\",\n",
    "    model=\"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "    revision=\"f2482bf\"  # 可选，锁定版本\n",
    ")\n",
    "```\n",
    "\n",
    "#### 2. **模型选择策略**\n",
    "- **任务适配性**：根据任务类型选择专用模型（如医疗 NER 用 `dslim/bert-base-NER`）。\n",
    "- **性能评估**：优先选择下载量高、社区评价好的模型（Hugging Face Hub 的筛选功能可辅助决策）。\n",
    "- **多语言支持**：非英文任务需选择多语言模型（如 `bert-base-multilingual-cased`）。\n",
    "\n",
    "#### 3. **版本控制**\n",
    "- 通过 `revision` 参数指定模型版本哈希值或分支名（如 `main`），确保代码长期稳定。\n",
    "- 示例：\n",
    "  ```python\n",
    "  pipeline(\"text-generation\", model=\"gpt2\", revision=\"6c0e608\")  # 指定版本哈希\n",
    "  ```\n",
    "\n",
    "#### 4. **环境配置优化**\n",
    "- **缓存管理**：通过 `MODELSCOPE_CACHE` 环境变量自定义模型存储路径（如 `/mnt/new_volume/hf/hub`），避免默认路径空间不足。\n",
    "- **GPU 加速**：添加 `device=0` 参数启用 GPU 推理（需安装 PyTorch/TensorFlow GPU 版本）。\n",
    "\n",
    "---\n",
    "\n",
    "### 三、扩展应用场景\n",
    "| 任务类型       | 推荐模型                          | 适用场景                     | 关键参数示例                     |\n",
    "|----------------|-----------------------------------|-----------------------------|----------------------------------|\n",
    "| **文本分类**   | `distilbert-base-uncased-finetuned-sst-2-english` | 情感分析、垃圾邮件检测       | `return_all_scores=True`         |\n",
    "| **问答系统**   | `bert-large-uncased-whole-word-masking-finetuned-squad` | 文档检索、客服机器人         | `top_k=3`（返回多个答案）        |\n",
    "| **文本生成**   | `gpt2` 或 `facebook/bart-large-cnn` | 内容创作、摘要生成           | `max_length=100, temperature=0.7` |\n",
    "\n",
    "---\n",
    "\n",
    "### 四、引用说明\n",
    "- 关于默认模型选择和版本控制问题，详见 Transformers 库的模型加载逻辑。\n",
    "- 生产环境最佳实践参考了 Hugging Face 官方文档的部署建议。\n",
    "- 模型选择策略结合了社区经验与 Hub 筛选机制。\n",
    "\n",
    "通过显式指定模型和版本，可避免默认行为的不确定性，同时提升代码可维护性和推理性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1ed125-f9ed-42d9-b102-dbc3172baefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /mnt/new_volume/hf/hub/models/hengzq/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"ner\", model=\"/mnt/new_volume/hf/hub/models/hengzq/bert-large-cased-finetuned-conll03-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68bab77c-0fe6-4781-b978-02d56829db33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'I-ORG', 'score': 0.9968, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}\n",
      "{'entity': 'I-ORG', 'score': 0.9293, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}\n",
      "{'entity': 'I-ORG', 'score': 0.9763, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}\n",
      "{'entity': 'I-MISC', 'score': 0.9983, 'index': 6, 'word': 'French', 'start': 18, 'end': 24}\n",
      "{'entity': 'I-LOC', 'score': 0.999, 'index': 10, 'word': 'New', 'start': 42, 'end': 45}\n",
      "{'entity': 'I-LOC', 'score': 0.9987, 'index': 11, 'word': 'York', 'start': 46, 'end': 50}\n",
      "{'entity': 'I-LOC', 'score': 0.9992, 'index': 12, 'word': 'City', 'start': 51, 'end': 55}\n"
     ]
    }
   ],
   "source": [
    "preds = classifier(\"Hugging Face is a French company based in New York City.\")\n",
    "preds = [\n",
    "    {\n",
    "        \"entity\": pred[\"entity\"],\n",
    "        \"score\": round(pred[\"score\"], 4),\n",
    "        \"index\": pred[\"index\"],\n",
    "        \"word\": pred[\"word\"],\n",
    "        \"start\": pred[\"start\"],\n",
    "        \"end\": pred[\"end\"],\n",
    "    }\n",
    "    for pred in preds\n",
    "]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa3eaaf-ce05-4858-8ce1-3c09eb9c63e8",
   "metadata": {},
   "source": [
    "用户提供的代码是在执行 **命名实体识别（NER）任务**，具体功能和警告解析如下：\n",
    "\n",
    "---\n",
    "\n",
    "### 一、代码功能解析\n",
    "#### 1. **模型加载与任务初始化**\n",
    "```python\n",
    "classifier = pipeline(\n",
    "    task=\"ner\",\n",
    "    model=\"/mnt/new_volume/hf/hub/models/hengzq/bert-large-cased-finetuned-conll03-english\"\n",
    ")\n",
    "```\n",
    "- **任务类型**: 使用 `task=\"ner\"` 初始化一个命名实体识别（NER）的 Pipeline。\n",
    "- **模型路径**: 加载本地存储的预训练模型 `bert-large-cased-finetuned-conll03-english`（该模型基于 CoNLL-2003 数据集微调，支持识别组织、人名、地点等实体）。\n",
    "\n",
    "#### 2. **推理与结果处理**\n",
    "```python\n",
    "text = \"Hugging Face is a French company based in New York City.\"\n",
    "preds = classifier(text)\n",
    "```\n",
    "- **输入文本**: 模型对句子进行分词和推理，识别文本中的实体。\n",
    "- **输出示例**:\n",
    "  ```python\n",
    "  {'entity': 'I-ORG', 'word': 'Hu', ...}  # \"Hugging Face\" 被识别为组织\n",
    "  {'entity': 'I-MISC', 'word': 'French'}  # \"French\" 被识别为其他类别\n",
    "  {'entity': 'I-LOC', 'word': 'New York City'}  # 地点识别\n",
    "  ```\n",
    "  - **实体类型**: `I-ORG`（组织）、`I-LOC`（地点）、`I-MISC`（其他类别）。\n",
    "  - **分词细节**: 由于 BERT 类模型使用子词分词，\"Hugging\" 被拆分为 `Hu` 和 `##gging`，但 Pipeline 会自动合并连续实体。\n",
    "\n",
    "#### 3. **结果格式化**\n",
    "```python\n",
    "preds = [\n",
    "    {\"entity\": pred[\"entity\"], \"score\": round(pred[\"score\"], 4), ...}\n",
    "    for pred in preds\n",
    "]\n",
    "```\n",
    "- **目的**: 对原始输出进行格式化，提取关键字段（实体类型、置信度、词语位置等），并将置信度四舍五入到小数点后四位。\n",
    "\n",
    "---\n",
    "\n",
    "### 二、警告信息解读\n",
    "#### 1. **警告内容**\n",
    "```\n",
    "Some weights of the model checkpoint were not used: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
    "```\n",
    "- **原因**: 加载的模型（`BertForTokenClassification`）未使用原始 BERT 模型的 **池化层（Pooler）** 权重。\n",
    "- **池化层作用**: 在原始 BERT 中，池化层用于生成句子级别的表示（如文本分类任务），但在 Token 分类任务（如 NER）中不需要该层。\n",
    "\n",
    "#### 2. **是否正常？**\n",
    "- **正常情况**: 如果模型是从 **其他任务（如文本分类）** 迁移到 Token 分类任务，未使用池化层是预期的。例如，用户加载的模型 `bert-large-cased-finetuned-conll03-english` 是专门针对 NER 任务微调的，因此丢弃了池化层。\n",
    "- **异常情况**: 如果期望加载的模型与当前任务结构完全一致（例如从 NER 模型加载到 NER 模型），则可能存在问题（需检查模型文件是否损坏）。\n",
    "\n",
    "---\n",
    "\n",
    "### 三、扩展建议\n",
    "#### 1. **优化模型加载**\n",
    "若需消除警告，可显式指定 `ignore_mismatched_sizes=True`：\n",
    "```python\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"/mnt/new_volume/hf/hub/models/hengzq/...\",\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/mnt/new_volume/hf/hub/models/hengzq/...\")\n",
    "classifier = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "```\n",
    "\n",
    "#### 2. **实体合并策略**\n",
    "使用 `aggregation_strategy` 参数合并子词分片的实体：\n",
    "```python\n",
    "classifier = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "```\n",
    "输出示例：\n",
    "```python\n",
    "{'entity_group': 'ORG', 'word': 'Hugging Face', 'start': 0, 'end': 12}\n",
    "{'entity_group': 'MISC', 'word': 'French', 'start': 18, 'end': 24}\n",
    "{'entity_group': 'LOC', 'word': 'New York City', 'start': 42, 'end': 55}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 引用说明\n",
    "- 关于 NER 模型结构和池化层的作用参考了 Transformers 库的模型加载逻辑（网页2、网页6）。\n",
    "- 实体合并策略和 Pipeline 配置方法来自 Transformers 官方文档（网页4、网页10）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef169f8-defe-4770-928e-1433a2095ee6",
   "metadata": {},
   "source": [
    "池化层（Pooling Layer）是卷积神经网络（CNN）中的一种关键组件，主要用于对输入数据进行下采样操作，以降低数据维度、提取主要特征并增强模型的鲁棒性。以下是其核心要点：\n",
    "\n",
    "---\n",
    "\n",
    "### 一、池化层的定义与作用\n",
    "1. **基本定义**  \n",
    "   池化层通过滑动固定大小的窗口（如2x2或3x3）对输入特征图进行降采样，保留关键特征的同时减少数据量。这种操作不改变通道数，但会缩小特征图的空间尺寸（如将4x4的特征图变为2x2）。\n",
    "\n",
    "2. **核心作用**  \n",
    "   - **降维与计算优化**：通过减少特征图的尺寸，降低后续层的计算量和内存占用。例如，5x5的输入经过步长为2的池化后变为3x3，计算量减少约75%。\n",
    "   - **特征提取**：保留显著特征（如最大池化选择窗口内的最大值），过滤噪声和冗余信息。\n",
    "   - **增强模型鲁棒性**：提供平移、旋转和尺度不变性，使模型对输入的小变化不敏感。\n",
    "\n",
    "---\n",
    "\n",
    "### 二、池化层的常见类型\n",
    "1. **最大池化（Max Pooling）**  \n",
    "   - **操作**：取窗口内的最大值作为输出。例如，窗口\\[1, 3, 5, 6\\]的最大值为6。  \n",
    "   - **优势**：保留最显著特征，适用于边缘检测等任务。\n",
    "\n",
    "2. **平均池化（Average Pooling）**  \n",
    "   - **操作**：计算窗口内所有值的平均值。例如，窗口\\[1, 3, 5, 6\\]的平均值为3.75。  \n",
    "   - **适用场景**：平滑特征图，减少噪声影响。\n",
    "\n",
    "3. **全局池化（Global Pooling）**  \n",
    "   - **操作**：将整个特征图压缩为一个值（如全局最大或平均池化），常用于分类任务的最后一层。  \n",
    "   - **示例**：将14x14的特征图压缩为1x1，直接输入全连接层。\n",
    "\n",
    "---\n",
    "\n",
    "### 三、池化层的数学实现与参数\n",
    "1. **参数设置**  \n",
    "   - **窗口大小（kernel_size）**：如2x2或3x3。  \n",
    "   - **步长（stride）**：决定输出尺寸，默认与窗口大小一致（如2x2窗口步长为2时，4x4输入变为2x2输出）。  \n",
    "   - **填充（padding）**：通常为0，不扩展输入边缘。\n",
    "\n",
    "2. **输出尺寸公式**  \n",
    "   \\[\n",
    "   \\text{输出尺寸} = \\left\\lfloor \\frac{\\text{输入尺寸} - \\text{窗口大小} + 2 \\times \\text{padding}}{\\text{步长}} \\right\\rfloor + 1\n",
    "   \\]\n",
    "   例如，5x5输入、3x3窗口、步长2、无填充时，输出为2x2。\n",
    "\n",
    "---\n",
    "\n",
    "### 四、池化层的优缺点\n",
    "1. **优点**  \n",
    "   - **降低过拟合风险**：减少参数数量，抑制模型复杂度。  \n",
    "   - **高效计算**：降维后减少后续层的计算量。  \n",
    "   - **特征不变性**：对输入的小平移、旋转具有鲁棒性。\n",
    "\n",
    "2. **缺点**  \n",
    "   - **信息丢失**：池化操作可能丢失细节（如平均池化模糊特征）。  \n",
    "   - **固定操作**：池化规则不可学习，灵活性较低。\n",
    "\n",
    "---\n",
    "\n",
    "### 五、应用场景与改进方法\n",
    "1. **典型应用**  \n",
    "   - **图像分类**：如ResNet中通过池化层逐步压缩特征图尺寸。  \n",
    "   - **目标检测**：保留物体的关键位置信息。  \n",
    "   - **医疗影像分析**：提取病灶区域的显著特征。\n",
    "\n",
    "2. **改进方法**  \n",
    "   - **自适应池化（Adaptive Pooling）**：动态调整窗口大小以适应不同输入。  \n",
    "   - **金字塔池化（Spatial Pyramid Pooling）**：多尺度池化捕捉不同粒度特征。\n",
    "\n",
    "---\n",
    "\n",
    "### 六、与其他组件的关联\n",
    "- **与卷积层的关系**：池化层通常紧随卷积层，用于压缩特征图并增强特征抽象能力。  \n",
    "- **与全连接层的衔接**：全局池化可将多维特征图压缩为向量，直接输入分类层。\n",
    "\n",
    "---\n",
    "\n",
    "### 总结\n",
    "池化层通过下采样操作在保留关键特征的同时优化计算效率，是CNN中不可或缺的组件。尽管存在信息丢失等问题，但其在模型鲁棒性和计算性能上的优势使其广泛应用于图像处理、目标检测等领域。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c72d55-e574-444f-96bc-62704022a148",
   "metadata": {},
   "source": [
    "#### 合并实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b441191-6156-44b8-a323-db461ad06efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /mnt/new_volume/hf/hub/models/hengzq/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/root/miniconda3/envs/peft/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.9674639,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 0,\n",
       "  'end': 12},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.99828726,\n",
       "  'word': 'French',\n",
       "  'start': 18,\n",
       "  'end': 24},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99896103,\n",
       "  'word': 'New York City',\n",
       "  'start': 42,\n",
       "  'end': 55}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"ner\", model=\"/mnt/new_volume/hf/hub/models/hengzq/bert-large-cased-finetuned-conll03-english\", grouped_entities=True)\n",
    "classifier(\"Hugging Face is a French company based in New York City.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7736791b-9585-4534-9efe-3fae3b7b6ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "369dda97-bd1a-4cb0-9636-47c2308c6289",
   "metadata": {},
   "source": [
    "### Question Answering\n",
    "\n",
    "**Question Answering**(问答)是另一个token-level的任务，返回一个问题的答案，有时带有上下文（开放领域），有时不带上下文（封闭领域）。每当我们向虚拟助手提出问题时，例如询问一家餐厅是否营业，就会发生这种情况。它还可以提供客户或技术支持，并帮助搜索引擎检索您要求的相关信息。\n",
    "\n",
    "有两种常见的问答类型：\n",
    "\n",
    "- 提取式：给定一个问题和一些上下文，模型必须从上下文中提取出一段文字作为答案、\n",
    "  模型给定一个问题和一段上下文，然后直接从这段上下文中选取一部分文字作为答案。比如，你问虚拟助手“这家餐厅现在营业吗？”，如果提供了餐厅相关的描述，模型会在文本中找到一段直接回答该问题的信息。\n",
    "  \n",
    "- 生成式：给定一个问题和一些上下文，答案是根据上下文生成的；这种方法由`Text2TextGenerationPipeline`处理，而不是下面展示的`QuestionAnsweringPipeline`\n",
    "  模型给定问题和上下文后，不是直接从文本中选取答案，而是根据上下文生成一个新的回答。这种方法通常由 Text2TextGenerationPipeline 处理，而不是直接用 QuestionAnsweringPipeline。\n",
    "\n",
    "模型主页：https://huggingface.co/distilbert-base-cased-distilled-squad\n",
    "distilbert-base-cased-distilled-squad就是一个专门经过微调、用于提取式问答任务的模型。它在 SQuAD 数据集上训练过，能够比较好地从给定文本中抽取出答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5281b0b-6b57-4884-92e1-cc2677987360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(task=\"question-answering\", model=\"/mnt/new_volume/hf/hub/models/damotestx/distilbert-base-cased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca674a51-30a4-4dea-a443-e428925e990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9327, start: 30, end: 54, answer: huggingface/transformers\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"What is the name of the repository?\",\n",
    "    context=\"The name of the repository is huggingface/transformers\",\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2158feb-a528-410a-aabf-f3bd7f2726c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9458, start: 115, end: 122, answer: Beijing\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"What is the capital of China?\",\n",
    "    context=\"On 1 October 1949, CCP Chairman Mao Zedong formally proclaimed the People's Republic of China in Tiananmen Square, Beijing.\",\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1d7e5-6baa-4142-81c1-5d311c0440e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebd7483-99a5-4f2a-894c-13cf5a3b71b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d995cb85-ab8f-4b28-9413-1a83fa3e4c4d",
   "metadata": {},
   "source": [
    "### Summarization\n",
    "\n",
    "**Summarization**(文本摘要）从较长的文本中创建一个较短的版本，同时尽可能保留原始文档的大部分含义。摘要是一个序列到序列的任务；它输出比输入更短的文本序列。有许多长篇文档可以进行摘要，以帮助读者快速了解主要要点。法案、法律和财务文件、专利和科学论文等文档可以摘要，以节省读者的时间并作为阅读辅助工具。\n",
    "\n",
    "与问答类似，摘要有两种类型：\n",
    "\n",
    "- 提取式：从原始文本中识别和提取最重要的句子\n",
    "  这种方法直接从原文中识别出最重要的句子，然后将它们组合成摘要。它类似于从原始文档中剪辑出关键部分，但不会对句子内容进行修改或重新生成。\n",
    "\n",
    "- 生成式：从原始文本中生成目标摘要（可能包括输入文件中没有的新单词）；`SummarizationPipeline`使用生成式方法\n",
    "  这种方法则是通过模型生成一个新的摘要，这个摘要不仅仅是从原文中挑选出来的句子，而是模型在理解原文后生成的新的表述，可能包含原文中没有的词汇。Hugging Face 中的 SummarizationPipeline 使用的就是这种生成式方法。\n",
    "\n",
    "模型主页：https://huggingface.co/t5-base\n",
    "t5-base是一个经过预训练的生成模型，可以用于生成式摘要以及其他文本生成任务。通过这种方式，可以对长篇文档（如法律、财务文件、专利、科研论文等）进行自动摘要，帮助读者快速捕捉主要内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e028f36-2b50-4ae3-8dce-2f0ac685e8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[当前HF_ENDPOINT值]: https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"[当前HF_ENDPOINT值]:\", os.environ.get('HF_ENDPOINT', '未设置（默认官方地址）'))\n",
    "\n",
    "summarizer = pipeline(task=\"summarization\",\n",
    "                      model=\"t5-base\",\n",
    "                      min_length=8,\n",
    "                      max_length=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c760bbf-2ae4-4f84-bd5e-32c30ee6bd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the Transformer is the first sequence transduction model based entirely on attention . it replaces recurrent layers commonly used in encoder-decode'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    \"\"\"\n",
    "    In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, \n",
    "    replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. \n",
    "    For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. \n",
    "    On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. \n",
    "    In the former task our best model outperforms even all previously reported ensembles.\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b50ff52b-e61e-40cd-ab66-a591dc0c3b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'large language models (LLMs) are very large deep learning models pre-trained on vast amounts of data . transformers are capable of un'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    '''\n",
    "    Large language models (LLM) are very large deep learning models that are pre-trained on vast amounts of data. \n",
    "    The underlying transformer is a set of neural networks that consist of an encoder and a decoder with self-attention capabilities. \n",
    "    The encoder and decoder extract meanings from a sequence of text and understand the relationships between words and phrases in it.\n",
    "    Transformer LLMs are capable of unsupervised training, although a more precise explanation is that transformers perform self-learning. \n",
    "    It is through this process that transformers learn to understand basic grammar, languages, and knowledge.\n",
    "    Unlike earlier recurrent neural networks (RNN) that sequentially process inputs, transformers process entire sequences in parallel. \n",
    "    This allows the data scientists to use GPUs for training transformer-based LLMs, significantly reducing the training time.\n",
    "    '''\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af6dc87e-9e3d-49b7-84ca-dc81f421d861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the rapid development of artificial intelligence (AI) has raised significant ethical concerns . one major issue is algorithmic bias, where AI systems may perpetuate or'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    \"\"\"\n",
    "    The rapid development of artificial intelligence (AI) has raised significant ethical concerns. \n",
    "    One major issue is algorithmic bias, where AI systems may perpetuate or amplify existing societal biases \n",
    "    due to biased training data. For example, facial recognition technologies have shown higher error rates \n",
    "    for certain demographic groups. Another challenge is the lack of transparency in deep learning models, \n",
    "    often referred to as the 'black box' problem. Policymakers and researchers are advocating for the \n",
    "    implementation of AI ethics guidelines, including fairness audits and explainable AI (XAI) frameworks. \n",
    "    Additionally, the potential misuse of AI in autonomous weapons systems has sparked international debates \n",
    "    on regulation. Addressing these challenges requires collaboration between technologists, ethicists, and \n",
    "    legal experts to ensure AI benefits humanity equitably.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72315144-7fae-4848-af79-a70e428b2416",
   "metadata": {},
   "source": [
    "\n",
    "## Audio 音频处理任务\n",
    "\n",
    "音频和语音处理任务与其他模态略有不同，主要是因为音频作为输入是一个连续的信号。与文本不同，原始音频波形不能像句子可以被划分为单词那样被整齐地分割成离散的块。为了解决这个问题，通常在固定的时间间隔内对原始音频信号进行采样。如果在每个时间间隔内采样更多样本，采样率就会更高，音频更接近原始音频源。\n",
    "\n",
    "以前的方法是预处理音频以从中提取有用的特征。现在更常见的做法是直接将原始音频波形输入到特征编码器中，以提取音频表示。这样可以简化预处理步骤，并允许模型学习最重要的特征。\n",
    "\n",
    "### Audio classification\n",
    "\n",
    "**Audio classification**(音频分类)是一项将音频数据从预定义的类别集合中进行标记的任务。这是一个广泛的类别，具有许多具体的应用，其中一些包括：\n",
    "\n",
    "- 声学场景分类：使用场景标签（“办公室”、“海滩”、“体育场”）对音频进行标记。\n",
    "- 声学事件检测：使用声音事件标签（“汽车喇叭声”、“鲸鱼叫声”、“玻璃破碎声”）对音频进行标记。\n",
    "- 标记：对包含多种声音的音频进行标记（鸟鸣、会议中的说话人识别）。\n",
    "- 音乐分类：使用流派标签（“金属”、“嘻哈”、“乡村”）对音乐进行标记。\n",
    "\n",
    "模型主页：https://huggingface.co/superb/hubert-base-superb-er\n",
    "\n",
    "数据集主页：https://huggingface.co/datasets/superb#er\n",
    "\n",
    "```\n",
    "情感识别（ER）为每个话语预测一个情感类别。我们采用了最广泛使用的ER数据集IEMOCAP，并遵循传统的评估协议：我们删除不平衡的情感类别，只保留最后四个具有相似数量数据点的类别，并在标准分割的五折交叉验证上进行评估。评估指标是准确率（ACC）。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b2096-6d9c-4ca7-ad3a-ec268b5e32c9",
   "metadata": {},
   "source": [
    "### 音频处理任务的特点和一个具体的音频分类任务（包括情感识别）的介绍，主要说明如下：\n",
    "\n",
    "1. 音频信号的连续性\n",
    "\n",
    "与文本不同，原始音频是连续的波形数据，不能像文字那样简单地切分成单个单词。为了解决这个问题，通常会在固定时间间隔内对音频进行采样，采样率越高，数字化后的音频越接近原始声音。\n",
    "\n",
    "2. 特征提取方式的演进\n",
    "\n",
    "以前常用的做法是先预处理音频，提取出手工设计的特征，然后再输入模型。而现在，主流的方法是直接将原始音频波形输入到一个特征编码器中，由模型自动学习出最有用的特征，这简化了预处理步骤。\n",
    "\n",
    "3. 音频分类任务\n",
    "\n",
    "音频分类任务是指将一段音频数据标记为预定义的类别，比如：\n",
    "声学场景分类：例如判断一段录音是在“办公室”、“海滩”还是“体育场”环境中录制的。\n",
    "声学事件检测：识别音频中的具体事件，如“汽车喇叭声”、“玻璃破碎声”等。\n",
    "多标签标记：对一段音频中可能存在的多种声音进行标记，比如同时识别会议中的不同说话人或背景声音。\n",
    "音乐分类：根据音乐风格（例如“金属”、“嘻哈”、“乡村”）给音乐进行分类。\n",
    "\n",
    "4. 情感识别（ER）\n",
    "\n",
    "作为一种音频处理任务，情感识别旨在为每个话语预测一个情感类别。这里采用了常用的IEMOCAP数据集，并按照传统评估方法，只保留数据量比较平衡的四个情感类别，使用标准的五折交叉验证，评估指标为准确率（ACC）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d4c1e9-8a67-4c72-8dce-ab326e0bc3b6",
   "metadata": {},
   "source": [
    "#### 前置依赖包安装\n",
    "\n",
    "建议在命令行安装必要的音频数据处理包: ffmpeg\n",
    "\n",
    "```shell\n",
    "$apt update & apt upgrade\n",
    "$apt install -y ffmpeg\n",
    "$pip install ffmpeg ffmpeg-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e1f8a8d-75eb-49ab-9353-6c9d1f384cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at superb/hubert-base-superb-er were not used when initializing HubertForSequenceClassification: ['hubert.encoder.pos_conv_embed.conv.weight_g', 'hubert.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing HubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at superb/hubert-base-superb-er and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"audio-classification\", model=\"superb/hubert-base-superb-er\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "204a4159-d14d-4623-8340-93d15abcc549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4532, 'label': 'hap'},\n",
       " {'score': 0.3622, 'label': 'sad'},\n",
       " {'score': 0.0943, 'label': 'neu'},\n",
       " {'score': 0.0903, 'label': 'ang'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 Hugging Face Datasets 上的测试文件\n",
    "preds = classifier(\"https://hf-mirror.com/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62b53a33-aea4-4409-aed9-e0b59e99ada8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.3642, 'label': 'neu'},\n",
       " {'score': 0.3408, 'label': 'hap'},\n",
       " {'score': 0.2599, 'label': 'ang'},\n",
       " {'score': 0.0351, 'label': 'sad'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 Hugging Face Datasets 上的测试文件\n",
    "preds = classifier(\"https://hf-mirror.com/datasets/Narsil/asr_dummy/resolve/main/1.flac\")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2528bf81-8289-4bb9-bf2d-c0ce9f7e8b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4532, 'label': 'hap'},\n",
       " {'score': 0.3622, 'label': 'sad'},\n",
       " {'score': 0.0943, 'label': 'neu'},\n",
       " {'score': 0.0903, 'label': 'ang'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用本地的音频文件做测试\n",
    "preds = classifier(\"data/audio/mlk.flac\")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d042ec-622e-4bc9-af60-876c947662c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6826a83-f5a5-454e-ac16-1f215abef861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e073cd1f-ba16-40a7-a029-bbd5e2a53dee",
   "metadata": {},
   "source": [
    "### Automatic speech recognition（ASR）\n",
    "\n",
    "**Automatic speech recognition**（自动语音识别）将语音转录为文本。这是最常见的音频任务之一，部分原因是因为语音是人类交流的自然形式。如今，ASR系统嵌入在智能技术产品中，如扬声器、电话和汽车。我们可以要求虚拟助手播放音乐、设置提醒和告诉我们天气。\n",
    "\n",
    "但是，Transformer架构帮助解决的一个关键挑战是低资源语言。通过在大量语音数据上进行预训练，仅在一个低资源语言的一小时标记语音数据上进行微调，仍然可以产生与以前在100倍更多标记数据上训练的ASR系统相比高质量的结果。\n",
    "\n",
    "模型主页：https://huggingface.co/openai/whisper-small\n",
    "\n",
    "下面展示使用 `OpenAI Whisper Small` 模型实现 ASR 的 Pipeline API 示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68d14f8c-1571-4889-abd4-8fde09dc610a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/peft/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 使用 `model` 参数指定模型\n",
    "transcriber = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "316ebe18-9c8e-4ded-96b7-751304aa9122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' He hoped there would be stew for dinner, turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick, peppered, flour-fattened sauce.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = transcriber(\"https://hf-mirror.com/datasets/Narsil/asr_dummy/resolve/main/1.flac\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4cee0eaa-2b61-455b-9ca1-77b8d7b5c79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = transcriber(\"data/audio/mlk.flac\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d5e06-ac4a-4a56-be36-9e445751bda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "228b1482-1e13-4557-8d37-5d56e961b5c5",
   "metadata": {},
   "source": [
    "## Computer Vision 计算机视觉\n",
    "\n",
    "**Computer Vision**（计算机视觉）任务中最早成功之一是使用卷积神经网络（CNN）识别邮政编码数字图像。图像由像素组成，每个像素都有一个数值。这使得将图像表示为像素值矩阵变得容易。每个像素值组合描述了图像的颜色。\n",
    "\n",
    "计算机视觉任务可以通过以下两种通用方式解决：\n",
    "\n",
    "- 使用卷积来学习图像的层次特征，从低级特征到高级抽象特征。\n",
    "- 将图像分成块，并使用Transformer逐步学习每个图像块如何相互关联以形成图像。与CNN偏好的自底向上方法不同，这种方法有点像从一个模糊的图像开始，然后逐渐将其聚焦清晰。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940e8959-dd3f-4fef-a924-747e69b4daea",
   "metadata": {},
   "source": [
    "计算机视觉的任务就是让计算机“看懂”图像。最早的成功案例之一是用卷积神经网络（CNN）来识别邮政编码的数字。图像其实就是由一系列像素组成，每个像素都有一个数值代表其颜色，这样图像就可以表示成一个数字矩阵。\n",
    "\n",
    "解决计算机视觉问题有两种常见方法：\n",
    "\n",
    "卷积神经网络（CNN）方法\n",
    "这种方法利用卷积层逐层提取图像特征，从最简单的边缘、纹理（低级特征），到更复杂的形状和物体（高级特征）。这种自底向上的方法类似于从原始图像中一点点“拼凑”出整体的结构和内容。\n",
    "\n",
    "基于Transformer的方法\n",
    "这种方法将图像切分成若干小块（patches），然后使用Transformer来学习这些图像块之间的关系。它有点像先看到一个模糊的全局图像，然后逐步将图像中的细节“聚焦”清晰。这种方法更注重全局信息之间的相互联系，与CNN的局部特征提取形成对比。\n",
    "\n",
    "总结来说，计算机视觉的两种方法各有侧重：CNN善于从局部提取层次特征，而基于Transformer的方法更像是从全局出发，逐步构建图像细节。这两种方法都在不断推动计算机理解和处理图像的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1737ac44-39e8-4827-a3d0-5cc8372d7e8b",
   "metadata": {},
   "source": [
    "### 卷积神经网络（CNN）\n",
    "卷积神经网络（CNN）是一种专门用于处理图像和其他网格状数据的深度学习模型。它主要通过卷积操作来提取图像中的局部特征，例如边缘、纹理和形状，再逐层组合这些特征来识别更复杂的模式。CNN的基本构成包括：\n",
    "\n",
    "- **卷积层**：使用多个小的卷积核在输入图像上滑动，提取局部特征。\n",
    "- **激活函数**（如ReLU）：引入非线性，使模型能够学习复杂的模式。\n",
    "- **池化层**：对特征图进行下采样，减少数据维度和计算量，同时保持重要信息。\n",
    "- **全连接层**：在网络的后部，将提取到的特征整合起来，进行分类或回归任务。\n",
    "\n",
    "这种结构使CNN在图像识别、目标检测、语音识别等任务中表现优异。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0bf9f4-6413-409b-968e-f03ca0c88367",
   "metadata": {},
   "source": [
    "### Image Classificaiton\n",
    "\n",
    "**Image Classificaiton**(图像分类)将整个图像从预定义的类别集合中进行标记。像大多数分类任务一样，图像分类有许多实际用例，其中一些包括：\n",
    "\n",
    "- 医疗保健：标记医学图像以检测疾病或监测患者健康状况\n",
    "- 环境：标记卫星图像以监测森林砍伐、提供野外管理信息或检测野火\n",
    "- 农业：标记农作物图像以监测植物健康或用于土地使用监测的卫星图像\n",
    "- 生态学：标记动物或植物物种的图像以监测野生动物种群或跟踪濒危物种\n",
    "\n",
    "模型主页：https://huggingface.co/google/vit-base-patch16-224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffff69f-9caa-4047-ac12-ad3d0dff853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 微调适合自己特殊场景的模型\n",
    "\n",
    "这个思路的基本流程是：\n",
    "\n",
    "1. **选择预训练模型**：以现有的模型（例如 vit-base-patch16-224）为基础，该模型已经在大规模数据上预训练，学到了通用的视觉特征。\n",
    "\n",
    "2. **收集并准备数据**：根据你的特殊场景，收集标注好的数据。数据应该反映你应用场景中的具体类别和特点。\n",
    "\n",
    "3. **微调（Fine-tuning）**：在预训练模型的基础上，用你的场景数据进行微调。通过调整模型参数，使得模型在你的数据上表现更好，适应特定任务。\n",
    "\n",
    "4. **评估和优化**：在验证集上测试微调后的模型表现，必要时调整超参数和训练策略。\n",
    "\n",
    "这种方法利用了预训练模型强大的特征提取能力，同时通过微调让模型更好地适应你的实际应用场景，从而实现较高的准确率和鲁棒性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98ca9736-10b9-45b0-a3e3-925f153bab57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 5dca96d (https://hf-mirror.com/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/root/miniconda3/envs/peft/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline  # 从 transformers 库中导入 pipeline 函数\n",
    "\n",
    "# 创建一个图像分类的 pipeline\n",
    "# 这里会加载一个默认的预训练模型（例如基于 Vision Transformer 的模型）\n",
    "# 调用 pipeline(task=\"image-classification\") 后，返回的是一个专门用于图像分类任务的 pipeline 对象（通常是一个 ImageClassificationPipeline 实例）。\n",
    "# 这个对象内部已经加载了默认的预训练模型、图像预处理器和后处理器，并实现了 __call__ 方法，可以直接接收图像输入并输出分类结果。换句话说，它封装了整个图像分类的流程，使得你只需传入图像，就能得到模型的预测结果。\n",
    "classifier = pipeline(task=\"image-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8a41647-e8db-4d29-9dac-06c3c145acaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.4335, 'label': 'lynx, catamount'}\n",
      "{'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}\n",
      "{'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}\n",
      "{'score': 0.0239, 'label': 'Egyptian cat'}\n",
      "{'score': 0.0229, 'label': 'tiger cat'}\n"
     ]
    }
   ],
   "source": [
    "# 使用 classifier 对给定 URL 的图像进行分类预测\n",
    "\"\"\"\n",
    "当调用 `classifier(...)` 时，pipeline 会自动执行以下步骤：  \n",
    "\n",
    "1. 下载或加载图片（如果是 URL，会先下载图片）；  \n",
    "2. 对图片进行必要的预处理；  \n",
    "3. 使用加载好的预训练模型进行推理；  \n",
    "4. 返回模型预测的结果。  \n",
    "\n",
    "所以这一行代码执行后，就会直接开始图像识别任务，并返回相应的预测结果。\n",
    "\"\"\"\n",
    "preds = classifier(\n",
    "    \"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "# 对每个预测结果，将分数四舍五入到小数点后4位，并保留标签信息\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "# 逐行打印预测结果\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ecb60-ebb9-4f4e-82bc-21e79bb22d90",
   "metadata": {},
   "source": [
    "![](data/image/cat-chonk.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67592129-6430-4349-8016-7dde511ff69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.4335, 'label': 'lynx, catamount'}\n",
      "{'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}\n",
      "{'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}\n",
      "{'score': 0.0239, 'label': 'Egyptian cat'}\n",
      "{'score': 0.0229, 'label': 'tiger cat'}\n"
     ]
    }
   ],
   "source": [
    "# 使用本地图片（狼猫）\n",
    "preds = classifier(\n",
    "    \"data/image/cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8113c251-a648-4ea2-baa4-3081bb490c70",
   "metadata": {},
   "source": [
    "![](data/image/panda.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7e9b51a-d759-4398-9894-f10933dbed47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9962, 'label': 'giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca'}\n",
      "{'score': 0.0018, 'label': 'lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens'}\n",
      "{'score': 0.0002, 'label': 'ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus'}\n",
      "{'score': 0.0001, 'label': 'sloth bear, Melursus ursinus, Ursus ursinus'}\n",
      "{'score': 0.0001, 'label': 'brown bear, bruin, Ursus arctos'}\n"
     ]
    }
   ],
   "source": [
    "# 使用本地图片（熊猫）\n",
    "preds = classifier(\n",
    "    \"data/image/panda.jpg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67c8588-6ae3-482a-aba7-23ced742e7bd",
   "metadata": {},
   "source": [
    "![](data/image/tiger.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a02a9af-27aa-4a6e-a7aa-17e72ed3e12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9351, 'label': 'tiger, Panthera tigris'}\n",
      "{'score': 0.0591, 'label': 'tiger cat'}\n",
      "{'score': 0.0017, 'label': 'jaguar, panther, Panthera onca, Felis onca'}\n",
      "{'score': 0.0005, 'label': 'leopard, Panthera pardus'}\n",
      "{'score': 0.0005, 'label': 'lion, king of beasts, Panthera leo'}\n"
     ]
    }
   ],
   "source": [
    "# 使用本地图片（老虎）\n",
    "preds = classifier(\n",
    "    \"data/image/tiger.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f5fdb-2803-4f4f-9008-00dee9a6a557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8118a561-3dc9-4693-8c3b-3e29c37b4d71",
   "metadata": {},
   "source": [
    "### Object Detection\n",
    "\n",
    "与图像分类不同，目标检测在图像中识别多个对象以及这些对象在图像中的位置（由边界框定义）。目标检测的一些示例应用包括：\n",
    "\n",
    "- 自动驾驶车辆：检测日常交通对象，如其他车辆、行人和红绿灯\n",
    "- 遥感：灾害监测、城市规划和天气预报\n",
    "- 缺陷检测：检测建筑物中的裂缝或结构损坏，以及制造业产品缺陷\n",
    "\n",
    "模型主页：https://huggingface.co/facebook/detr-resnet-50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7122f04-7add-4623-8f3f-ccc00247524b",
   "metadata": {},
   "source": [
    "#### 前置依赖包安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cbc4227-cbcc-4f18-bf26-66535e66afb6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /root/miniconda3/lib/python3.11/site-packages (0.9.12)\n",
      "Requirement already satisfied: torch>=1.7 in /root/miniconda3/lib/python3.11/site-packages (from timm) (2.3.0.dev20240116+cu121)\n",
      "Requirement already satisfied: torchvision in /root/miniconda3/lib/python3.11/site-packages (from timm) (0.18.0.dev20240117+cu121)\n",
      "Requirement already satisfied: pyyaml in /root/miniconda3/lib/python3.11/site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /root/miniconda3/lib/python3.11/site-packages (from timm) (0.20.1)\n",
      "Requirement already satisfied: safetensors in /root/miniconda3/lib/python3.11/site-packages (from timm) (0.4.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (4.8.0)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (1.11.1)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (3.0rc1)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (2023.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: pytorch-triton==2.2.0+e28a256d71 in /root/miniconda3/lib/python3.11/site-packages (from torch>=1.7->timm) (2.2.0+e28a256d71)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /root/miniconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7->timm) (12.1.105)\n",
      "Collecting fsspec (from torch>=1.7->timm)\n",
      "  Using cached fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.11/site-packages (from huggingface-hub->timm) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/miniconda3/lib/python3.11/site-packages (from huggingface-hub->timm) (4.66.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /root/miniconda3/lib/python3.11/site-packages (from huggingface-hub->timm) (23.2)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/lib/python3.11/site-packages (from torchvision->timm) (1.24.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /root/miniconda3/lib/python3.11/site-packages (from torchvision->timm) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.11/site-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /root/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/miniconda3/lib/python3.11/site-packages (from sympy->torch>=1.7->timm) (1.2.1)\n",
      "Using cached fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "Installing collected packages: fsspec\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 2.16.1 requires fsspec[http]<=2023.10.0,>=2023.1.0, but you have fsspec 2023.12.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2023.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3401126-756b-4394-930c-c833c1f574b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/detr-resnet-50 and revision 2729413 (https://huggingface.co/facebook/detr-resnet-50).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/root/miniconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libpng16.so.16: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "detector = pipeline(task=\"object-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32dc65d4-3868-4d10-a433-9f50832e8e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9864,\n",
       "  'label': 'cat',\n",
       "  'box': {'xmin': 178, 'ymin': 154, 'xmax': 882, 'ymax': 598}}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = detector(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550759be-93ab-4988-81f0-c0cb8eccfda8",
   "metadata": {},
   "source": [
    "![](data/image/cat_dog.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40f66cd7-f2c8-4af3-b9ab-60012792ec1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9985,\n",
       "  'label': 'cat',\n",
       "  'box': {'xmin': 78, 'ymin': 57, 'xmax': 309, 'ymax': 371}},\n",
       " {'score': 0.989,\n",
       "  'label': 'dog',\n",
       "  'box': {'xmin': 279, 'ymin': 20, 'xmax': 482, 'ymax': 416}}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = detector(\n",
    "    \"data/image/cat_dog.jpg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d591246-662b-47e0-8531-f862b05ba1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1565e1d-20bf-4b19-86c1-dd3a8983a999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4993a9f-1032-46ab-97b1-a028d4bd5ebc",
   "metadata": {},
   "source": [
    "### Homework：替换以上示例中的模型，对比不同模型在相同任务上的性能表现\n",
    "\n",
    "在 Hugging Face Models 中找到适合你的模型：https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f51d2-863d-44f6-836f-9051351985ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
